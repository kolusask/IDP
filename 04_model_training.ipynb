{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchmetrics as tm\n",
    "\n",
    "from config import *\n",
    "from stages import *\n",
    "from train import *\n",
    "\n",
    "from data.util import crop_q_between, split_weekdays_and_weekends\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = tm.MeanSquaredError().to(CONFIG.device)\n",
    "mape = tm.MeanAbsolutePercentageError().to(CONFIG.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([35040, 472])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_q = CONFIG.load('mat_q.pt')\n",
    "mat_q.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compare MSE and MAPE losses for different parameter configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 1: Pre-train RBMs + attach KELM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P=3125, N=4, Loss=21906222.76\n",
      "P=3125, N=8, Loss=21906222.76\n",
      "P=3125, N=12, Loss=21906222.76\n",
      "P=3125, N=16, Loss=21906222.76\n",
      "P=3125, N=20, Loss=21906222.76\n",
      "P=3125, N=24, Loss=21906222.76\n",
      "P=3125, N=28, Loss=21906222.76\n",
      "P=3125, N=32, Loss=21906222.76\n",
      "P=28125, N=4, Loss=7449782.47\n",
      "P=28125, N=8, Loss=7449782.47\n",
      "P=28125, N=12, Loss=7449782.47\n",
      "P=28125, N=16, Loss=7449782.47\n",
      "P=28125, N=20, Loss=7449782.47\n",
      "P=28125, N=24, Loss=7449782.47\n",
      "P=28125, N=28, Loss=7449782.47\n",
      "P=28125, N=32, Loss=7449782.47\n",
      "P=3125, N=4, Loss=30824.5703125\n",
      "P=3125, N=8, Loss=30824.5703125\n",
      "P=3125, N=12, Loss=30824.5703125\n",
      "P=3125, N=16, Loss=30824.5703125\n",
      "P=3125, N=20, Loss=30824.5703125\n",
      "P=3125, N=24, Loss=30824.5703125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 21\u001b[0m\n\u001b[1;32m     17\u001b[0m train_c, val_c, test_c \u001b[39m=\u001b[39m split_train_val_test(\n\u001b[1;32m     18\u001b[0m     mat_c_we, \u001b[39m*\u001b[39mCONFIG\u001b[39m.\u001b[39mdata_split)\n\u001b[1;32m     19\u001b[0m train_dataset \u001b[39m=\u001b[39m SlidingWindowDataset(\n\u001b[1;32m     20\u001b[0m     train_c\u001b[39m.\u001b[39mT, CONFIG\u001b[39m.\u001b[39mtime_window_length, \u001b[39m1\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m kelm \u001b[39m=\u001b[39m fit_kelm_to_dbn(dbn, train_dataset)\n\u001b[1;32m     23\u001b[0m test_dataloader \u001b[39m=\u001b[39m DataLoader(SlidingWindowDataset(\n\u001b[1;32m     24\u001b[0m     train_c\u001b[39m.\u001b[39mT, CONFIG\u001b[39m.\u001b[39mtime_window_length, \u001b[39m1\u001b[39m))\n\u001b[1;32m     25\u001b[0m mse_loss \u001b[39m=\u001b[39m \u001b[39m0.\u001b[39m\n",
      "File \u001b[0;32m~/TUM/IDP/IDP/src/train.py:101\u001b[0m, in \u001b[0;36mfit_kelm_to_dbn\u001b[0;34m(dbn, dataset)\u001b[0m\n\u001b[1;32m     98\u001b[0m kelm_y \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mconcatenate(kelm_y)[:, \u001b[39mNone\u001b[39;00m]\n\u001b[1;32m    100\u001b[0m kelm \u001b[39m=\u001b[39m KELM()\n\u001b[0;32m--> 101\u001b[0m kelm\u001b[39m.\u001b[39;49mfit(kelm_X, kelm_y)\n\u001b[1;32m    103\u001b[0m \u001b[39mreturn\u001b[39;00m kelm\n",
      "File \u001b[0;32m~/TUM/IDP/IDP/src/prediction_models/kelm.py:18\u001b[0m, in \u001b[0;36mKELM.fit\u001b[0;34m(self, X, y, reg_coeff, gamma)\u001b[0m\n\u001b[1;32m     16\u001b[0m omega \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_kernel(X, X)\n\u001b[1;32m     17\u001b[0m \u001b[39m# self._beta = torch.inverse(torch.eye(M, device=X.device) / reg_coeff + omega) @ y\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_beta \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mpinverse(omega) \u001b[39m@\u001b[39m y\n\u001b[1;32m     19\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data \u001b[39m=\u001b[39m X\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Weekday/Weekend > P > N := MSE\n",
    "results_1 = {}\n",
    "\n",
    "for P in range(3125, 28125, 3125):\n",
    "    CONFIG.spectral_threshold = P\n",
    "    dbn = get_pre_trained_dbn(CONFIG, print_each=0)\n",
    "    for N in range(4, 36, 4):\n",
    "        CONFIG.dbn_hidden_layer_sizes = [N, N, N]\n",
    "\n",
    "        mat_q_trend, mat_q_resid = preprocess_data(P, mat_q)\n",
    "        mat_c, mat_x = compress_data(\n",
    "            mat_q_resid.abs(), CONFIG.read_period, CONFIG.train_period, CONFIG.alpha)\n",
    "\n",
    "        mat_c_wd, mat_c_we = split_weekdays_and_weekends(\n",
    "            mat_c, CONFIG.train_period[0])\n",
    "\n",
    "        train_c, val_c, test_c = split_train_val_test(\n",
    "            mat_c_we, *CONFIG.data_split)\n",
    "        train_dataset = SlidingWindowDataset(\n",
    "            train_c.T, CONFIG.time_window_length, 1)\n",
    "        kelm = fit_kelm_to_dbn(dbn, train_dataset)\n",
    "\n",
    "        test_dataloader = DataLoader(SlidingWindowDataset(\n",
    "            train_c.T, CONFIG.time_window_length, 1))\n",
    "        mse_loss = 0.\n",
    "        n_samples = 0\n",
    "        for X, y in test_dataloader:\n",
    "            n_samples += 1\n",
    "            pred = dbn(X).squeeze()\n",
    "            pred = kelm(pred).T\n",
    "\n",
    "            mse_loss += mse(pred, y).item()\n",
    "        mse_loss /= n_samples\n",
    "        print(f'P={P}, N={N}, Loss={mse_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 2: Pre-train DBN + Train DBN attaching KELM on each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2.4297e-06, device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Echo(torch.nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    def forward(x):\n",
    "        return x\n",
    "\n",
    "random_dataset = BinaryVectorDataset(1000, 10)\n",
    "print(len(random_dataset))\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for X_, y_ in DataLoader(random_dataset):\n",
    "    X.append(X_.to(CONFIG.device))\n",
    "    y.append(y_.to(CONFIG.device))\n",
    "\n",
    "X = torch.concat(X)\n",
    "y = torch.concat(y)\n",
    "\n",
    "kelm = KELM()\n",
    "kelm.fit(X, y)\n",
    "mse(kelm(X[4:8]).squeeze(), y[4:8].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".idp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

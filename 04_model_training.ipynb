{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torchmetrics as tm\n",
    "\n",
    "from config import *\n",
    "from stages import *\n",
    "from train import *\n",
    "from data.ssa import SSA\n",
    "\n",
    "from data.util import crop_q_between, split_weekdays_and_weekends\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0025,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0073, 0.0100,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0150,  ..., 0.0039, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.0095, 0.0290, 0.0698,  ..., 0.0000, 0.0463, 0.0000],\n",
       "        [0.0000, 0.0163, 0.0175,  ..., 0.0000, 0.0256, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = tm.MeanSquaredError().to(CONFIG.device)\n",
    "mape = tm.MeanAbsolutePercentageError().to(CONFIG.device)\n",
    "mat_q = CONFIG.load('mat_q.pt')\n",
    "CONFIG.alpha = 0.2\n",
    "CONFIG.alpha = 1000\n",
    "mat_c_all, mat_x_repr, nonempty, representatives = compress_data(\n",
    "    mat_q.abs(), CONFIG.read_period, CONFIG.train_period, CONFIG.alpha)\n",
    "mat_q = mat_q[:, mat_q.sum(dim=0) > 0]\n",
    "normalizing_constants_all = mat_q.max(dim=0)[0]\n",
    "mat_q /= normalizing_constants_all\n",
    "mat_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([35040, 357])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_q.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compare MSE and MAPE losses for different parameter configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-train DBN and Train DBN attaching KELM on each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Representatives: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/kolusask/TUM/IDP/IDP/src/data/ssa.py:153: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3614.)\n",
      "  P = U.T[:, :-1].permute(2, 0, 1)\n",
      "356it [38:50:08, 392.72s/it]\n"
     ]
    }
   ],
   "source": [
    "results_wd = {}\n",
    "results_we = {}\n",
    "\n",
    "ssa = SSA(4, [2, 2], CONFIG.device)\n",
    "\n",
    "CONFIG.spectral_threshold = 1440\n",
    "CONFIG.dbn_hidden_layer_sizes = [80, 80, 80]\n",
    "\n",
    "gamma = 1\n",
    "reg_coeff = 1\n",
    "\n",
    "\n",
    "for gamma in [gamma]:#range(1, 26, 5):\n",
    "  for reg_coeff in [reg_coeff]:#range(1, 102, 25):\n",
    "    for P in [40,]:#range(125, 3125, 125):\n",
    "      results_P = {}\n",
    "      CONFIG.spectral_threshold = P\n",
    "      for N in [84,]:#range(4, 324, 80):\n",
    "        CONFIG.dbn_hidden_layer_sizes = [N, N, N]\n",
    "\n",
    "        mat_c_all, mat_x_all, nonempty, representatives = compress_data(\n",
    "            mat_q.abs(), CONFIG.read_period, CONFIG.train_period, CONFIG.alpha)\n",
    "        mat_q_trend_all, mat_q_resid_all = preprocess_data(\n",
    "            CONFIG.spectral_threshold, mat_c_all)\n",
    "        mat_q_resid_all = crop_q_between(mat_q_resid_all, CONFIG.read_period,\n",
    "                                         CONFIG.train_period).real\n",
    "        mat_c_all = crop_q_between(\n",
    "            mat_c_all, CONFIG.read_period, CONFIG.train_period)\n",
    "\n",
    "        print('Representatives: ' + str(representatives.tolist()))\n",
    "        # while mat_c.shape[1] == 1:\n",
    "        #   CONFIG.alpha += 0.01\n",
    "        #   print(f'alpha={CONFIG.alpha}')\n",
    "        #   mat_c, mat_x, nonempty, representatives = compress_data(\n",
    "        #     mat_q_resid.abs(), CONFIG.read_period, CONFIG.train_period,\n",
    "        #     CONFIG.alpha)\n",
    "        # mat_q_trend_all = mat_q_trend[:, nonempty][:, representatives].abs()\n",
    "        for section_index, section_number in tqdm(enumerate(representatives.tolist())):\n",
    "          mat_q_trend = mat_q_trend_all[:, section_index][:, None].real\n",
    "          mat_q_resid = mat_q_resid_all[:, section_index][:, None].real\n",
    "\n",
    "          norm_const = normalizing_constants_all[section_number].item()\n",
    "\n",
    "          (_, val_trend_wd_dataloader, _), (_, val_trend_we_dataloader, _) = \\\n",
    "            crop_and_split_mat(mat_q_trend, CONFIG, separate_weekends=False)\n",
    "          # (_, val_resid_wd_dataloader, _), (_, val_resid_we_dataloader, _) =\n",
    "          #   crop_and_split_mat(mat_q_resid, CONFIG)\n",
    "          mat_c_wd_datasets, mat_c_we_datasets = split_mat(mat_q_resid, CONFIG)\n",
    "          # print(gamma, reg_coeff, P, N, mat_c.shape)\n",
    "\n",
    "          del mat_q_resid\n",
    "\n",
    "          dbn, kelm, val_resid_we_dataloader = train_with_config(\n",
    "              CONFIG, mat_c_we_datasets, dbn_training_epochs=100, stride=1,\n",
    "              gamma=gamma, reg_coeff=reg_coeff)\n",
    "          prefix = f'alpha{CONFIG.alpha}_p{P}_n{N}_sec{section_number}_'\\\n",
    "            .replace('.', '_')\n",
    "          CONFIG.save(dbn.state_dict(), prefix + 'dbn.pt')\n",
    "          CONFIG.save(kelm.state_dict(), prefix + 'kelm.pt')\n",
    "\n",
    "          # continue\n",
    "\n",
    "          mse_loss_trend = torch.tensor([0.,]).to(CONFIG.device)\n",
    "          mse_loss_resid = torch.tensor([0.,]).to(CONFIG.device)\n",
    "          mse_loss_overall = torch.tensor([0.,]).to(CONFIG.device)\n",
    "          mse_loss_trend_unnorm = torch.tensor([0.,]).to(CONFIG.device)\n",
    "          mse_loss_resid_unnorm = torch.tensor([0.,]).to(CONFIG.device)\n",
    "          mse_loss_overall_unnorm = torch.tensor([0.,]).to(CONFIG.device)\n",
    "\n",
    "          trend_y = torch.tensor([0.,]).to(CONFIG.device)\n",
    "          resid_y = torch.tensor([0.,]).to(CONFIG.device)\n",
    "          overall_y = torch.tensor([0.,]).to(CONFIG.device)\n",
    "\n",
    "          iter_trend = iter(val_trend_we_dataloader)\n",
    "          n_samples = 0\n",
    "\n",
    "          resid = {'y': [], 'pred': []}\n",
    "          trend = {'y': [], 'pred': []}\n",
    "          overall = {'y': [], 'pred': []}\n",
    "          for X_resid, y_resid in val_resid_we_dataloader:\n",
    "              resid_y += y_resid.item()\n",
    "              X_trend, y_trend = next(iter_trend)\n",
    "              trend_y += y_trend.item()\n",
    "              pred_trend = ssa.forecast(\n",
    "                  X_trend.squeeze(0).T, 1).sum(0)[-1][None]\n",
    "              mse_loss_trend += mse(pred_trend, y_trend)\n",
    "              mse_loss_trend_unnorm += mse(pred_trend * norm_const, y_trend * norm_const)\n",
    "              trend['y'].append(y_trend.item() * norm_const)\n",
    "              trend['pred'].append(pred_trend.item() * norm_const)\n",
    "              # print('TREND', y_trend, pred_trend)\n",
    "\n",
    "              pred_resid = dbn(X_resid).squeeze(0)\n",
    "              pred_resid = kelm(pred_resid).T\n",
    "              mse_loss_resid += mse(pred_resid, y_resid)\n",
    "              mse_loss_resid_unnorm += mse(pred_resid * norm_const, y_resid * norm_const)\n",
    "              resid['y'].append(y_resid.item() * norm_const)\n",
    "              resid['pred'].append(pred_resid.item() * norm_const)\n",
    "\n",
    "              # print('RESID', y_resid, pred_resid)\n",
    "\n",
    "              pred = pred_trend + pred_resid\n",
    "\n",
    "              y = y_trend + y_resid\n",
    "              overall_y += y.item()\n",
    "              overall['y'].append(y.item() * norm_const)\n",
    "              overall['pred'].append(pred.item() * norm_const)\n",
    "              # print('OVRLL', y, pred)\n",
    "              # print('=====')\n",
    "\n",
    "              mse_loss_overall += mse(pred, y).item()\n",
    "              mse_loss_overall_unnorm += mse(pred * norm_const, y * norm_const).item()\n",
    "              n_samples += 1\n",
    "\n",
    "          mse_loss_trend /= n_samples\n",
    "          mse_loss_resid /= n_samples\n",
    "          mse_loss_overall /= n_samples\n",
    "          mse_loss_resid_unnorm /= n_samples\n",
    "          mse_loss_trend_unnorm /= n_samples\n",
    "          mse_loss_overall_unnorm /= n_samples\n",
    "\n",
    "          resid_y /= n_samples\n",
    "          trend_y /= n_samples\n",
    "          overall_y /= n_samples\n",
    "\n",
    "          results_P[section_number] = {\n",
    "              'resid': resid,\n",
    "              'trend': trend,\n",
    "              'overall': overall\n",
    "          }\n",
    "\n",
    "          # print(f'gamma={gamma}, reg_coeff={reg_coeff}, ' +\n",
    "          #       f'WE P={CONFIG.spectral_threshold}, ' +\n",
    "          #       f'N={CONFIG.dbn_hidden_layer_sizes}, ' +\n",
    "          #       f'trend={trend_y.item()}+-{mse_loss_trend.item()}' +\n",
    "          #       f'~{mse_loss_trend_unnorm.item()}, ' +\n",
    "          #       f'resid={resid_y.item()}+-{mse_loss_resid.item()}' +\n",
    "          #       f'~{mse_loss_resid_unnorm.item()}, ' +\n",
    "          #       f'overall={overall_y.item()}+-{mse_loss_overall.item()}' +\n",
    "          #       f'~{mse_loss_overall_unnorm.item()}')\n",
    "          del dbn\n",
    "          del kelm\n",
    "      results_we[P] = results_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('results_we_norm_all.json', 'w') as file:\n",
    "  json.dump(results_we, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_wd = {}\n",
    "# results_we = {}\n",
    "\n",
    "# ssa = SSA(4, [2, 2], CONFIG.device)\n",
    "\n",
    "# CONFIG.spectral_threshold = 1440\n",
    "# CONFIG.dbn_hidden_layer_sizes = [80, 80, 80]\n",
    "\n",
    "# gamma = 1\n",
    "# reg_coeff = 1\n",
    "\n",
    "# CONFIG.alpha = 0.2#0.779\n",
    "\n",
    "# mat_q_trend_full, mat_q_resid_full = preprocess_data(CONFIG.spectral_threshold, mat_q)\n",
    "# (_, val_full_trend_wd_dataloader, _), (_, val_full_trend_we_dataloader, _) = \\\n",
    "#   crop_and_split_mat(mat_q_trend_full, CONFIG, separate_weekends=False)\n",
    "# (_, val_full_resid_wd_dataloader, _), (_, val_full_resid_we_dataloader, _) = \\\n",
    "#   crop_and_split_mat(mat_q_resid_full, CONFIG, separate_weekends=False)\n",
    "# (_, val_full_overall_wd_dataloader, _), (_, val_full_overall_we_dataloader, _) = \\\n",
    "#   crop_and_split_mat(mat_q, CONFIG, separate_weekends=False)\n",
    "# mat_q_we_full = torch.row_stack([d[1] for d in val_full_overall_we_dataloader])\n",
    "# mat_q_trend_we_full = torch.row_stack([d[1] for d in val_full_trend_we_dataloader])\n",
    "# mat_q_resid_we_full = torch.row_stack([d[1] for d in val_full_resid_we_dataloader])\n",
    "\n",
    "# results_P = {}\n",
    "# for alpha in range(...): # TBD\n",
    "#   mat_c_repr, mat_x, nonempty, representatives = compress_data(\n",
    "#       mat_q.abs(), CONFIG.read_period, CONFIG.train_period, CONFIG.alpha)\n",
    "#   mat_q_trend_repr, mat_q_resid_repr = preprocess_data(\n",
    "#       CONFIG.spectral_threshold, mat_c_repr)\n",
    "#   mat_q_resid_repr = crop_q_between(mat_q_resid_repr, CONFIG.read_period,\n",
    "#                                     CONFIG.train_period).real\n",
    "#   mat_c_repr = crop_q_between(\n",
    "#       mat_c_repr, CONFIG.read_period, CONFIG.train_period)\n",
    "\n",
    "#   print('Representatives: ' + str(representatives.tolist()))\n",
    "#   mat_c_trend_pred = []\n",
    "#   mat_c_resid_pred = []\n",
    "#   mat_c_pred = []\n",
    "#   for section_index, section_number in enumerate(representatives.tolist()):#[[0, representatives.tolist()[2]]]\n",
    "#     mat_q_trend = mat_q_trend_repr[:, section_index][:, None].real\n",
    "#     mat_q_resid = mat_q_resid_repr[:, section_index][:, None].real\n",
    "\n",
    "#     norm_const = normalizing_constants_all[section_number].item()\n",
    "#     norm_const = 1\n",
    "\n",
    "#     (_, val_trend_wd_dataloader, _), (_, val_trend_we_dataloader, _) = \\\n",
    "#       crop_and_split_mat(mat_q_trend, CONFIG, separate_weekends=False)\n",
    "#     mat_c_wd_datasets, mat_c_we_datasets = split_mat(mat_q_resid, CONFIG)\n",
    "\n",
    "#     del mat_q_resid\n",
    "\n",
    "#     dbn, kelm, val_resid_we_dataloader = train_with_config(\n",
    "#         CONFIG, mat_c_we_datasets, dbn_training_epochs=1, stride=1,\n",
    "#         gamma=gamma, reg_coeff=reg_coeff)\n",
    "#     prefix = f'alpha{CONFIG.alpha}_p{P}_n{N}_sec{section_number}_'\\\n",
    "#       .replace('.', '_')\n",
    "#     CONFIG.save(dbn.state_dict(), prefix + 'dbn.pt')\n",
    "#     CONFIG.save(kelm.state_dict(), prefix + 'kelm.pt')\n",
    "\n",
    "#     iter_trend = iter(val_trend_we_dataloader)\n",
    "#     n_samples = 0\n",
    "\n",
    "#     trend = []\n",
    "#     resid = []\n",
    "#     overall = []\n",
    "\n",
    "#     for X_resid, y_resid in val_resid_we_dataloader:\n",
    "#         X_trend, y_trend = next(iter_trend)\n",
    "#         pred_trend = ssa.forecast(\n",
    "#             X_trend.squeeze(0).T, 1).sum(0)[-1][None]\n",
    "#         trend.append(pred_trend.item())\n",
    "\n",
    "#         pred_resid = dbn(X_resid).squeeze(0)\n",
    "#         pred_resid = kelm(pred_resid).T\n",
    "#         resid.append(pred_resid.item())\n",
    "\n",
    "#         pred = pred_trend + pred_resid\n",
    "#         overall.append(pred.item())\n",
    "\n",
    "#         y = y_trend + y_resid\n",
    "\n",
    "#         n_samples += 1\n",
    "\n",
    "#     mat_c_trend_pred.append(trend)\n",
    "#     mat_c_resid_pred.append(resid)\n",
    "#     mat_c_pred.append(overall)\n",
    "\n",
    "#     results_P[section_number] = {\n",
    "#         'resid': resid,\n",
    "#         'trend': trend,\n",
    "#         'overall': overall\n",
    "#     }\n",
    "\n",
    "#     del dbn\n",
    "#     del kelm\n",
    "  \n",
    "#   mat_c_trend_pred = torch.tensor(mat_c_trend_pred)\n",
    "#   mat_c_resid_pred = torch.tensor(mat_c_resid_pred)\n",
    "#   mat_c_pred = torch.tensor(mat_c_pred)\n",
    "\n",
    "#   mat_c_trend_gt = mat_q_trend_we_full[:, representatives]\n",
    "#   mat_c_resid_gt = mat_q_resid_we_full[:, representatives]\n",
    "#   mat_c_gt = mat_q_we_full[:, representatives]\n",
    "\n",
    "#   mat_x_trend = torch.linalg.pinv(mat_c_trend_gt) @ mat_q_trend_we_full\n",
    "#   mat_x_resid = torch.linalg.pinv(mat_c_resid_gt) @ mat_q_resid_we_full\n",
    "\n",
    "#   mat_q_we_pred = mat_c_pred @ mat_x\n",
    "#   mat_q_trend_pred = mat_c_trend_pred @ mat_x_trend\n",
    "#   mat_q_resid_pred = mat_c_resid_pred @ mat_x_resid\n",
    "\n",
    "  \n",
    "\n",
    "# results_we[P] = results_P\n",
    "# print(results_we)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mat_c_trend_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mat_c_trend_pred\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mat_c_trend_pred' is not defined"
     ]
    }
   ],
   "source": [
    "mat_c_trend_pred.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".idp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

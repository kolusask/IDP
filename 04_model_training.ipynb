{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torchmetrics as tm\n",
    "\n",
    "from config import *\n",
    "from stages import *\n",
    "from train import *\n",
    "from data.ssa import SSA\n",
    "\n",
    "from data.util import crop_q_between, split_weekdays_and_weekends\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG.device = 'cpu'\n",
    "mse = tm.MeanSquaredError().to(CONFIG.device)\n",
    "mape = tm.MeanAbsolutePercentageError().to(CONFIG.device)\n",
    "mat_q = CONFIG.load('mat_q.pt')\n",
    "CONFIG.alpha = 0.07\n",
    "mat_q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compare MSE and MAPE losses for different parameter configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-train DBN and Train DBN attaching KELM on each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_wd = {}\n",
    "results_we = {}\n",
    "\n",
    "ssa = SSA(4, [2, 2], CONFIG.device)\n",
    "\n",
    "CONFIG.spectral_threshold = 1440\n",
    "CONFIG.dbn_hidden_layer_sizes = [80, 80, 80]\n",
    "\n",
    "gamma = 1\n",
    "reg_coeff = 1\n",
    "\n",
    "for gamma in [gamma]:#range(1, 26, 5):\n",
    "  for reg_coeff in [reg_coeff]:#range(1, 102, 25):\n",
    "    for P in range(3125 * 4, 25001, 3125):\n",
    "        CONFIG.spectral_threshold = P\n",
    "        for N in range(4, 324, 80):\n",
    "          CONFIG.dbn_hidden_layer_sizes = [N, N, N]\n",
    "\n",
    "          mat_q_trend, mat_q_resid = preprocess_data(CONFIG.spectral_threshold, mat_q)\n",
    "          mat_c, mat_x, nonempty, representatives = compress_data(\n",
    "              mat_q_resid.abs(), CONFIG.read_period, CONFIG.train_period, CONFIG.alpha)\n",
    "          while mat_c.shape[1] == 1:\n",
    "            CONFIG.alpha += 0.01\n",
    "            print(f'alpha={CONFIG.alpha}')\n",
    "            mat_c, mat_x, nonempty, representatives = compress_data(\n",
    "              mat_q_resid.abs(), CONFIG.read_period, CONFIG.train_period, CONFIG.alpha)\n",
    "          mat_q_trend = mat_q_trend[:, nonempty][:, representatives].abs()\n",
    "\n",
    "          (_, val_trend_wd_dataloader, _), (train_trend_we_dataloader, val_trend_we_dataloader, _) = crop_and_split_mat(mat_q_trend, CONFIG)\n",
    "          # (_, val_resid_wd_dataloader, _), (_, val_resid_we_dataloader, _) = crop_and_split_mat(mat_q_resid, CONFIG)\n",
    "          mat_c_wd_datasets, mat_c_we_datasets = split_mat(mat_c, CONFIG)\n",
    "          print(gamma, reg_coeff, P, N, mat_c.shape)\n",
    "\n",
    "          del mat_c\n",
    "\n",
    "          dbn, kelm, val_resid_we_dataloader = train_with_config(CONFIG, mat_c_we_datasets, dbn_training_epochs=1000, stride=1, gamma=gamma, reg_coeff=reg_coeff)\n",
    "\n",
    "          mse_loss_trend = torch.tensor([0.,]).to(CONFIG.device)\n",
    "          mse_loss_resid = torch.tensor([0.,]).to(CONFIG.device)\n",
    "          mse_loss_overall = torch.tensor([0.,]).to(CONFIG.device)\n",
    "          iter_trend = iter(val_trend_we_dataloader)\n",
    "          n_samples = 0\n",
    "          for X_resid, y_resid in val_resid_we_dataloader:\n",
    "              X_trend, y_trend = next(iter_trend)\n",
    "              pred_trend = ssa.forecast(X_trend.squeeze().T, 1).sum(0)[-1][None]\n",
    "              mse_loss_trend += mse(pred_trend, y_trend)\n",
    "              # print('TREND', y_trend, pred_trend)\n",
    "\n",
    "              pred_resid = dbn(X_resid).squeeze()\n",
    "              pred_resid = kelm(pred_resid).T\n",
    "              mse_loss_resid += mse(pred_resid, y_resid)\n",
    "              # print('RESID', y_resid, pred_resid)\n",
    "\n",
    "              pred = pred_trend + pred_resid\n",
    "\n",
    "              y = y_trend + y_resid\n",
    "              # print('OVRLL', y, pred)\n",
    "              # print('=====')\n",
    "\n",
    "              mse_loss_overall += mse(pred, y)\n",
    "              n_samples += 1\n",
    "\n",
    "          mse_loss_trend /= n_samples\n",
    "          mse_loss_resid /= n_samples\n",
    "          mse_loss_overall /= n_samples\n",
    "\n",
    "          print(f'gamma={gamma}, reg_coeff={reg_coeff}, WE P={CONFIG.spectral_threshold}, N={CONFIG.dbn_hidden_layer_sizes}, Loss_trend={mse_loss_trend.item()}, Loss_resid={mse_loss_resid.item()}, Loss_overall={mse_loss_overall.item()}')\n",
    "          del dbn\n",
    "          del kelm\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".idp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "from csv import QUOTE_NONE\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "if 'src' not in sys.path:\n",
    "    sys.path.append('src')\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from explore.data import DetectorDataProvider, LookUpTable\n",
    "from explore.graph import IntersectionGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from the data set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get list of all sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lut = LookUpTable('Data')\n",
    "sections = set()\n",
    "for inter in lut.list_intersections():\n",
    "    detectors = lut.get_detectors_on(inter)\n",
    "    for sec in detectors[['Starting Intersection', 'Ending Intersection']].values:\n",
    "        sections.add(tuple(sorted(sec)))\n",
    "pprint(list(sections)[:10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract list of detectors for each section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lut = LookUpTable('Data')\n",
    "def construct_int_det(sections):\n",
    "    int_det = []\n",
    "    for int_1, int_2 in sections:\n",
    "        det_1_2, det_2_1 = lut.get_detectors_between(int_1, int_2)\n",
    "        int_det.append((int_1, int_2, det_1_2))\n",
    "        int_det.append((int_2, int_1, det_2_1))\n",
    "    int_det = pd.DataFrame(int_det, columns=['Start', 'End', 'Detectors'])\n",
    "    \n",
    "    return int_det\n",
    "    \n",
    "int_det = construct_int_det(sections)\n",
    "int_det"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract data from January to August and accumulate counts by section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddp = DetectorDataProvider('Data')\n",
    "ddp.list_intersections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE = datetime(2021, 1, 1)\n",
    "END_DATE = datetime(2021, 12, 1)\n",
    "\n",
    "def count_traffic(int_det, start_date=START_DATE, end_date=END_DATE):\n",
    "    lens = set()\n",
    "    def get_count(section_end, detectors):\n",
    "        section_data = ddp.get_data_for_period(section_end, START_DATE, END_DATE)\n",
    "        for col in section_data.columns:\n",
    "            section_data[col] = pd.to_numeric(section_data[col], errors='coerce')\n",
    "        try:\n",
    "            return list(section_data[detectors].fillna(0).sum(axis=1, numeric_only=True).cumsum())\n",
    "        except KeyError:\n",
    "            print(section_end, section_data.columns, detectors)\n",
    "    int_det['Counts'] = int_det.apply(lambda sec: get_count(sec['End'], sec['Detectors']), axis=1)\n",
    "\n",
    "count_traffic(int_det)\n",
    "int_det.to_hdf('int_det_excluded_missing.hdf', 'int_det')\n",
    "int_det"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write data into a matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write counts into a matrix\n",
    "$$Q=[q_1,q_2,...,q_p]$$\n",
    "for\n",
    "$$q_i=\\set{z(s_i,t_1),z(s_i,t_2),...z(s_i,t_d)}^T,$$\n",
    "$z(s_i,t_j)$ is the traffic flow of the road section $s_i$ within the time interval $(t_0,t_j)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_q(int_det: pd.DataFrame):\n",
    "    mat_q = torch.tensor(int_det['Counts'].tolist()).T\n",
    "    return mat_q\n",
    "\n",
    "mat_q = construct_q(int_det)\n",
    "torch.save(mat_q, 'mat_q_excluded_missing.pt')\n",
    "mat_q.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load matrix $Q$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_q = torch.load('mat_q_excluded_missing.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32064, 468])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_q_fft = torch.abs(torch.fft.fft(mat_q, dim=0))\n",
    "mat_q_fft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mat_q_fft[:, 0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data compression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a correlation coefficient matrix\n",
    "$$\n",
    "R(i, j)=\\frac{\\sum_{k=1}^d(z(s_i,t_k)-\\tilde{z}(s_i))(z(s_j,t_k)-\\tilde{z}(s_j))}{\\sqrt{\\sum_{k=1}^d(z(s_i,t_k)-\\tilde{z}(s_i))^2}\\sqrt{\\sum_{k=1}^d(z(s_j,t_k)-\\tilde{z}(s_j))^2}},\n",
    "$$\n",
    "where $$\\tilde{z}(s_i)=\\frac{1}{d}\\sum_{k=1}^dz(s_i,t_k)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_r(mat_q, ignore: set=None):\n",
    "    if ignore is None:\n",
    "        ignore = set()\n",
    "    d, p = mat_q.shape\n",
    "    mat_q_normalized = mat_q - mat_q.mean(dim=0)\n",
    "    mat_r = torch.zeros(p, p)\n",
    "    for i in range(p):\n",
    "        for j in range(i, p):\n",
    "            if (i, j) in ignore:\n",
    "                mat_r[i][j] = 0.0\n",
    "            else:\n",
    "                i_col = mat_q_normalized[:, i]\n",
    "                j_col = mat_q_normalized[:, j]\n",
    "                i_norm = max(torch.norm(i_col), 1e-12)\n",
    "                j_norm = max(torch.norm(j_col), 1e-12)\n",
    "                if i_norm == 0 or j_norm == 0:\n",
    "                    if i_norm == j_norm:\n",
    "                        mat_r[i][j] = 1\n",
    "                    else:\n",
    "                        mat_r[i][j] = 0\n",
    "                else:\n",
    "                    mat_r[i][j] = (i_col @ j_col) / i_norm / j_norm\n",
    "            mat_r[j][i] = mat_r[i][j]\n",
    "    return mat_r\n",
    "\n",
    "mat_r = construct_r(mat_q)\n",
    "torch.save(mat_r, 'mat_r_excluded_missing.pt')\n",
    "mat_r"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load matrices R and Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_q = torch.load('mat_q_excluded_missing.pt')\n",
    "mat_r = torch.load('mat_r_excluded_missing.pt')\n",
    "mat_r = mat_r / mat_r.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = 0.9999\n",
    "\n",
    "n_timesteps, n_sections = mat_q.shape\n",
    "n_grouped = 0\n",
    "groups = []\n",
    "\n",
    "mat_r_copy = mat_r - torch.diag(mat_r.diag())\n",
    "while n_grouped < n_sections:\n",
    "    new_group_idx = torch.nonzero(mat_r_copy > ALPHA)\n",
    "    if len(new_group_idx) > 0:\n",
    "        corr = mat_r[new_group_idx[:, 0], new_group_idx[:, 1]]\n",
    "        new_group_idx = new_group_idx[:, 0].unique()\n",
    "\n",
    "        n_grouped += len(new_group_idx)\n",
    "        mat_r_copy[new_group_idx, :] = 0\n",
    "        mat_r_copy[:, new_group_idx] = 0\n",
    "        groups.append((new_group_idx, corr.min(), corr.max()))\n",
    "        if mat_r_copy.max() == 0:\n",
    "            break\n",
    "        else:\n",
    "            mat_r_copy /= mat_r_copy.max()\n",
    "del mat_r_copy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Using alpha={ALPHA}, {n_sections} correlated sections were divided ' +\n",
    "      f'into {len(groups)} groups:')\n",
    "n_ungrouped = 0\n",
    "for i, (group, corr_min, corr_max) in enumerate(groups, start=1):\n",
    "      group_coeffs = mat_r[tuple(group.T), :]\n",
    "      print(f'Group {i} - {len(group)} sections with correlation coefficients '\n",
    "          f'{corr_min:.3f} to {corr_max:.3f}')\n",
    "print(str(n_sections - n_grouped) + \" section(s) don't correlate with anything and weren't grouped\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "representatives = torch.stack([g[0] for g, _, _ in groups])\n",
    "mat_c = mat_q[:, representatives]\n",
    "assert mat_c.shape == (mat_q.shape[0], len(groups))\n",
    "torch.save(mat_c, 'mat_c_excluded_missing.pt')\n",
    "mat_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_x = torch.linalg.pinv(mat_c) @ mat_q\n",
    "torch.save(mat_x, 'mat_x_excluded_missing.pt')\n",
    "mat_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.max((mat_c @ mat_x) - mat_q))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".idp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "912fb52f238e5d0393cd3cb39c1046be4cbf42cc336ebf4385af401bc969f2f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

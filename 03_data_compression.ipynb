{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "from config import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data.compress import *\n",
    "from data.util import count_points_in_period, crop_q_between\n",
    "\n",
    "from torchmetrics import MeanSquaredError as MSE, MeanAbsolutePercentageError as MAPE\n",
    "\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load matrix $Q$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_q = CONFIG.load('mat_q.pt')\n",
    "mat_q = torch.abs(mat_q)\n",
    "mat_q.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crop $Q$ to the required time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_sections = mat_q.shape\n",
    "mat_q = crop_q_between(mat_q, CONFIG.read_period, CONFIG.train_period)\n",
    "assert mat_q.shape == (count_points_in_period(CONFIG.train_period), n_sections)\n",
    "mat_q.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a correlation coefficient matrix\n",
    "$$\n",
    "R(i, j)=\\frac{\\sum_{k=1}^d(z(s_i,t_k)-\\tilde{z}(s_i))(z(s_j,t_k)-\\tilde{z}(s_j))}{\\sqrt{\\sum_{k=1}^d(z(s_i,t_k)-\\tilde{z}(s_i))^2}\\sqrt{\\sum_{k=1}^d(z(s_j,t_k)-\\tilde{z}(s_j))^2}},\n",
    "$$\n",
    "where $$\\tilde{z}(s_i)=\\frac{1}{d}\\sum_{k=1}^dz(s_i,t_k)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_r, nonempty = build_correlation_matrix(mat_q, True)\n",
    "mat_q = mat_q[:, nonempty]\n",
    "mat_r.shape, nonempty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_groups = []\n",
    "for alpha in torch.arange(0, 1.05, 0.05):\n",
    "    print(alpha)\n",
    "    groups = split_sections_into_groups(mat_r, alpha)\n",
    "    alpha_groups.append([alpha, len(groups)])\n",
    "alpha_groups = torch.tensor(alpha_groups)\n",
    "alpha_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(alpha_groups[:, 0], alpha_groups[:, 1])\n",
    "plt.xlabel(r'Correlation coefficient $\\alpha$')\n",
    "plt.ylabel('Number of groups')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_groups = []\n",
    "for alpha in torch.arange(0.9, 1.01, 0.01):\n",
    "    groups = split_sections_into_groups(mat_r, alpha)\n",
    "    alpha_groups.append([alpha, len(groups)])\n",
    "alpha_groups = torch.tensor(alpha_groups)\n",
    "alpha_groups"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, n_sections = mat_q.shape\n",
    "print(f'Using alpha={CONFIG.alpha}, {n_sections} correlated sections were divided ' +\n",
    "      f'into {len(groups)} groups:')\n",
    "for i, group in enumerate(groups, start=1):\n",
    "      print(f'Group {i} - {len(group)} sections: {\", \".join(str(s) for s in group)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = MSE().to(CONFIG.device)\n",
    "mape = MAPE().to(CONFIG.device)\n",
    "\n",
    "from stages import compress_data\n",
    "\n",
    "def losses_for_alpha(alpha):\n",
    "    # groups = split_sections_into_groups(mat_r, alpha)\n",
    "    # mat_c, representatives = get_compression_matrix(mat_q, groups)\n",
    "    # mat_q.shape, mat_c.shape\n",
    "    # x = torch.linalg.pinv(mat_c) @ mat_q\n",
    "    # reproduce = mat_c @ x\n",
    "\n",
    "    mat_q = CONFIG.load('mat_q.pt')\n",
    "    mat_c, mat_x, nonempty, representatives = compress_data(mat_q, CONFIG.read_period, CONFIG.test_period, alpha)\n",
    "    mat_q = crop_q_between(mat_q[:, nonempty], CONFIG.read_period, CONFIG.test_period)\n",
    "    _reproduce = decompress(mat_c, mat_x)\n",
    "\n",
    "    return mse(mat_q.T, _reproduce.T), mape(mat_q.T, _reproduce.T)\n",
    "\n",
    "def losses_for_alpha_range(begin, end, step = None):\n",
    "    if step is None:\n",
    "        step = float(end - begin) / 10\n",
    "    losses = []\n",
    "    for alpha in torch.arange(begin, end, step).to(CONFIG.device):\n",
    "        losses.append(torch.stack([alpha, *losses_for_alpha(alpha)]))\n",
    "    losses = torch.stack(losses).T\n",
    "\n",
    "    return losses\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 3))\n",
    "losses = losses_for_alpha_range(0.0, 1.0, 0.01)\n",
    "axes[0].set_title('Mean Squared Error')\n",
    "axes[0].plot(losses[0].cpu(), losses[1].cpu())\n",
    "axes[0].set_xlabel(r'Correlation coefficient $\\alpha$')\n",
    "axes[0].set_ylabel('Error')\n",
    "axes[1].set_title('Mean Average Percentage Error')\n",
    "axes[1].plot(losses[0].cpu(), losses[2].cpu())\n",
    "axes[1].set_xlabel(r'Correlation coefficient $\\alpha$')\n",
    "\n",
    "print(losses[0][torch.where(losses[1] < 100)])\n",
    "print(losses[0][torch.where(losses[2] < 100)])\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 3))\n",
    "losses = losses_for_alpha_range(0.0, 1.0, 0.01)\n",
    "losses_mse = losses_for_alpha_range(0.94, 1.0)\n",
    "losses_mape = losses_for_alpha_range(0.92, 1.0)\n",
    "axes[0].set_title('Mean Squared Error')\n",
    "axes[0].plot(losses_mse[0].cpu(), losses_mse[1].cpu())\n",
    "axes[0].set_xlabel(r'Correlation threshold $\\alpha$')\n",
    "axes[0].set_ylabel('Error')\n",
    "axes[1].set_title('Mean Average Percentage Error')\n",
    "axes[1].plot(losses_mape[0].cpu(), losses_mape[2].cpu())\n",
    "axes[1].set_xlabel(r'Correlation threshold $\\alpha$')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_c, representatives = get_compression_matrix(mat_q, groups)\n",
    "\n",
    "assert mat_c.shape == (mat_q.shape[0], len(groups))\n",
    "CONFIG.save(mat_c, 'mat_c.pt')\n",
    "mat_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_x = get_compressed_matrix(mat_c, mat_q)\n",
    "CONFIG.save(mat_x, 'mat_x.pt')\n",
    "mat_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(torch.abs((mat_c @ mat_x) - mat_q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = split_sections_into_groups(mat_r, 0.99)\n",
    "[(i, g) for i, g in enumerate(groups) if len(g) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missing(alpha):\n",
    "    groups = split_sections_into_groups(mat_r, alpha)\n",
    "    _, representatives = get_compression_matrix(mat_q, groups)\n",
    "    n_sections = mat_q.shape[1]\n",
    "    present = torch.zeros(n_sections, dtype=bool)\n",
    "    present[representatives] = True\n",
    "    return ~present\n",
    "\n",
    "missing_099 = get_missing(0.99)\n",
    "\n",
    "for alpha in torch.concat([\n",
    "    torch.arange(0, 0.95, 0.05),\n",
    "    torch.arange(0.9, 1.0, 0.01)\n",
    "]):\n",
    "    missing_alpha = get_missing(alpha)\n",
    "    missing_both = torch.bitwise_and(missing_099, missing_alpha)\n",
    "    assert missing_099.sum() == missing_both.sum()\n",
    "\n",
    "CONFIG.save(torch.where(missing_099), 'missing_0.99.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".idp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "912fb52f238e5d0393cd3cb39c1046be4cbf42cc336ebf4385af401bc969f2f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
